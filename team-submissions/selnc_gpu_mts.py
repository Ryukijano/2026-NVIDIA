#!/usr/bin/env python3
"""
Enhanced GPU-Accelerated Memetic Tabu Search (MTS) for LABS Problem
Integrated with SELNC Quantum Seeding

Features:
- Fully vectorized energy computation using CuPy
- Batch neighbor evaluation on GPU
- Population-parallel local search
- Quantum-enhanced initialization via SELNC
- Comprehensive timing and profiling

Target: iQuHACK 2026 NVIDIA Challenge - Phase 2
Hardware: NVIDIA B300 GPU with 30 CPUs
"""

import numpy as np
import time
from copy import deepcopy
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass

# GPU acceleration via CuPy
try:
    import cupy as cp
    GPU_AVAILABLE = True
    print(f"CuPy {cp.__version__} available - GPU acceleration enabled")
except ImportError:
    GPU_AVAILABLE = False
    print("CuPy not available - falling back to NumPy CPU implementation")
    cp = np

# =============================================================================
# LABS ENERGY FUNCTIONS (VECTORIZED)
# =============================================================================

def labs_energy_cpu(sequence: np.ndarray) -> float:
    """CPU implementation of LABS energy"""
    N = len(sequence)
    energy = 0.0
    for k in range(1, N):
        C_k = np.sum(sequence[:-k] * sequence[k:])
        energy += C_k ** 2
    return energy

def labs_autocorrelation_vectorized(sequence, xp=np):
    """Vectorized autocorrelation computation"""
    N = len(sequence)
    seq = xp.asarray(sequence, dtype=xp.float32)
    C = xp.zeros(N - 1, dtype=xp.float32)
    for k in range(1, N):
        C[k - 1] = xp.sum(seq[:-k] * seq[k:])
    return C

def labs_energy_vectorized(sequence, xp=np) -> float:
    """Vectorized LABS energy computation"""
    C = labs_autocorrelation_vectorized(sequence, xp)
    energy = xp.sum(C ** 2)
    return float(energy) if xp != np else energy

# =============================================================================
# GPU-ACCELERATED MTS CLASS
# =============================================================================

@dataclass
class MTSConfig:
    """Configuration for MTS algorithm"""
    num_generations: int = 50
    pop_size: int = 20
    p_mutate: float = 0.1
    tabu_size: int = 20
    tabu_iterations: int = 100
    use_gpu: bool = True

@dataclass  
class MTSResult:
    """Result container for MTS run"""
    best_solution: np.ndarray
    best_energy: float
    energy_history: List[float]
    timing: Dict[str, float]
    device: str
    generations_run: int

class EnhancedGPUMTS:
    """
    Enhanced GPU-Accelerated Memetic Tabu Search for LABS
    
    GPU Acceleration Strategy:
    1. Vectorized energy calculation using CuPy
    2. Batch neighbor evaluation - all N neighbors in parallel
    3. Population stored in GPU memory for reduced transfers
    4. Parallel fitness evaluation across population
    """
    
    def __init__(self, N: int, config: MTSConfig = None):
        self.N = N
        self.config = config or MTSConfig()
        self.use_gpu = self.config.use_gpu and GPU_AVAILABLE
        self.xp = cp if self.use_gpu else np
        self.device = 'GPU' if self.use_gpu else 'CPU'
        
        # Pre-allocate GPU memory for batch operations
        if self.use_gpu:
            self._preallocate_gpu_buffers()
        
        # Timing profiler
        self.timing = {
            'energy_calc': 0.0,
            'neighbor_eval': 0.0,
            'tabu_search': 0.0,
            'crossover': 0.0,
            'total': 0.0
        }
    
    def _preallocate_gpu_buffers(self):
        """Pre-allocate GPU memory buffers for efficiency"""
        self.neighbor_buffer = cp.zeros((self.N, self.N), dtype=cp.float32)
        self.energy_buffer = cp.zeros(self.N, dtype=cp.float32)
    
    def calculate_autocorrelation(self, seq) -> np.ndarray:
        """Calculate autocorrelations C_k using vectorized operations"""
        return labs_autocorrelation_vectorized(seq, self.xp)
    
    def calculate_energy(self, seq) -> float:
        """Compute LABS energy with GPU acceleration"""
        t0 = time.perf_counter()
        energy = labs_energy_vectorized(seq, self.xp)
        self.timing['energy_calc'] += time.perf_counter() - t0
        return energy
    
    def batch_neighbor_energies(self, current: np.ndarray) -> np.ndarray:
        """
        GPU-ACCELERATED: Evaluate all N single-bit flip neighbors in parallel
        
        This is the key optimization - instead of N sequential energy calculations,
        we compute all N neighbors on GPU in one batch.
        """
        t0 = time.perf_counter()
        
        current_gpu = self.xp.asarray(current, dtype=self.xp.float32)
        N = len(current_gpu)
        
        if self.use_gpu:
            # Create all N neighbors as a batch matrix
            neighbors = cp.tile(current_gpu, (N, 1))
            # Flip each bit along diagonal
            flip_indices = cp.arange(N)
            neighbors[flip_indices, flip_indices] *= -1
            
            # Compute energies in parallel
            energies = cp.zeros(N, dtype=cp.float32)
            for i in range(N):
                C = labs_autocorrelation_vectorized(neighbors[i], cp)
                energies[i] = cp.sum(C ** 2)
            
            result = cp.asnumpy(energies)
        else:
            # CPU fallback
            energies = np.zeros(N, dtype=np.float32)
            for i in range(N):
                neighbor = current.copy()
                neighbor[i] *= -1
                energies[i] = labs_energy_vectorized(neighbor, np)
            result = energies
        
        self.timing['neighbor_eval'] += time.perf_counter() - t0
        return result
    
    def batch_population_energies(self, population: List[np.ndarray]) -> np.ndarray:
        """Compute energies for entire population in parallel on GPU"""
        t0 = time.perf_counter()
        
        if self.use_gpu:
            pop_gpu = cp.array(population, dtype=cp.float32)
            energies = cp.zeros(len(population), dtype=cp.float32)
            
            for i in range(len(population)):
                C = labs_autocorrelation_vectorized(pop_gpu[i], cp)
                energies[i] = cp.sum(C ** 2)
            
            result = cp.asnumpy(energies)
        else:
            result = np.array([labs_energy_vectorized(ind, np) for ind in population])
        
        self.timing['energy_calc'] += time.perf_counter() - t0
        return result
    
    def tabu_search_gpu(self, current: np.ndarray, 
                        tabu_size: int = None, 
                        num_iterations: int = None) -> Tuple[np.ndarray, float]:
        """
        GPU-Optimized Tabu Search with batch neighbor evaluation
        """
        t0 = time.perf_counter()
        
        tabu_size = tabu_size or self.config.tabu_size
        num_iterations = num_iterations or self.config.tabu_iterations
        
        current = np.asarray(current, dtype=np.float32)
        best = current.copy()
        best_energy = self.calculate_energy(best)
        tabu_set = set()
        
        for iteration in range(num_iterations):
            # GPU: Batch evaluate all neighbors
            neighbor_energies = self.batch_neighbor_energies(current)
            
            # Find best non-tabu neighbor
            best_neighbor_idx = None
            best_neighbor_energy = float('inf')
            
            for i in range(len(current)):
                # Create neighbor tuple for tabu check
                neighbor_tuple = tuple(current.copy())
                neighbor_tuple = tuple(-current[j] if j == i else current[j] 
                                      for j in range(len(current)))
                
                if neighbor_tuple not in tabu_set and neighbor_energies[i] < best_neighbor_energy:
                    best_neighbor_energy = neighbor_energies[i]
                    best_neighbor_idx = i
            
            if best_neighbor_idx is None:
                break
            
            # Move to best neighbor
            current[best_neighbor_idx] *= -1
            
            # Update tabu list (FIFO)
            tabu_set.add(tuple(current))
            if len(tabu_set) > tabu_size:
                # Remove oldest entry
                tabu_set = set(list(tabu_set)[-tabu_size:])
            
            # Update global best
            if best_neighbor_energy < best_energy:
                best = current.copy()
                best_energy = best_neighbor_energy
        
        self.timing['tabu_search'] += time.perf_counter() - t0
        return best, best_energy
    
    def crossover(self, p1: np.ndarray, p2: np.ndarray) -> np.ndarray:
        """Single-point crossover"""
        t0 = time.perf_counter()
        cut = np.random.randint(1, len(p1))
        child = np.concatenate([p1[:cut], p2[cut:]])
        self.timing['crossover'] += time.perf_counter() - t0
        return child
    
    def mutate(self, seq: np.ndarray, p_mutate: float = None) -> np.ndarray:
        """Bit-flip mutation"""
        p_mutate = p_mutate or self.config.p_mutate
        child = seq.copy()
        mask = np.random.random(len(child)) < p_mutate
        child[mask] *= -1
        return child
    
    def run(self, initial_population: List[np.ndarray] = None,
            verbose: bool = True) -> MTSResult:
        """
        Run GPU-Accelerated MTS algorithm
        
        Args:
            initial_population: Optional quantum-seeded population
            verbose: Print progress
        
        Returns:
            MTSResult with best solution, energy history, timing
        """
        start_time = time.perf_counter()
        self.timing = {k: 0.0 for k in self.timing}  # Reset timing
        
        N = self.N
        pop_size = self.config.pop_size
        num_generations = self.config.num_generations
        
        # Initialize population
        if initial_population is not None:
            population = [np.asarray(ind, dtype=np.float32) for ind in initial_population[:pop_size]]
            # Fill remaining slots if needed
            while len(population) < pop_size:
                population.append(np.random.choice([-1, 1], size=N).astype(np.float32))
        else:
            population = [np.random.choice([-1, 1], size=N).astype(np.float32) 
                         for _ in range(pop_size)]
        
        # Compute initial energies
        energies = self.batch_population_energies(population)
        
        best_idx = np.argmin(energies)
        best_solution = population[best_idx].copy()
        best_energy = energies[best_idx]
        energy_history = [best_energy]
        
        for gen in range(num_generations):
            new_population = []
            
            for _ in range(pop_size):
                # Tournament selection
                p1_idx = np.random.randint(0, pop_size)
                p2_idx = np.random.randint(0, pop_size)
                
                # Crossover
                child = self.crossover(population[p1_idx], population[p2_idx])
                
                # Mutation
                child = self.mutate(child)
                
                # Local search with tabu
                child, child_energy = self.tabu_search_gpu(child)
                
                # Update global best
                if child_energy < best_energy:
                    best_solution = child.copy()
                    best_energy = child_energy
                
                new_population.append(child)
            
            # Compute new energies
            new_energies = self.batch_population_energies(new_population)
            
            # Combine and select best
            combined_pop = population + new_population
            combined_energies = np.concatenate([energies, new_energies])
            
            # Sort by energy and keep best pop_size
            sorted_indices = np.argsort(combined_energies)[:pop_size]
            population = [combined_pop[i] for i in sorted_indices]
            energies = combined_energies[sorted_indices]
            
            energy_history.append(best_energy)
            
            if verbose and (gen + 1) % 10 == 0:
                print(f"Gen {gen+1}/{num_generations} | Best: {best_energy:.2f} | Device: {self.device}")
        
        self.timing['total'] = time.perf_counter() - start_time
        
        return MTSResult(
            best_solution=best_solution,
            best_energy=best_energy,
            energy_history=energy_history,
            timing=self.timing.copy(),
            device=self.device,
            generations_run=num_generations
        )

# =============================================================================
# QUANTUM-CLASSICAL HYBRID WORKFLOW
# =============================================================================

class QuantumEnhancedMTS:
    """
    Hybrid Quantum-Classical workflow combining SELNC with GPU-MTS
    
    Pipeline:
    1. SELNC quantum circuit generates initial seed population
    2. GPU-accelerated MTS refines solutions
    3. Results compared against random-seeded MTS baseline
    """
    
    def __init__(self, N: int, mts_config: MTSConfig = None):
        self.N = N
        self.mts_config = mts_config or MTSConfig()
        self.mts = EnhancedGPUMTS(N, self.mts_config)
        
        # Try to import SELNC solver
        try:
            from selnc_quantum import SELNCSolver
            self.selnc_available = True
            self.selnc = SELNCSolver(N, cd_order=2, init_mode="palindromic")
        except ImportError:
            self.selnc_available = False
            self.selnc = None
            print("Warning: SELNC quantum solver not available")
    
    def run_quantum_seeded(self, quantum_shots: int = 100, 
                           quantum_steps: int = 10,
                           verbose: bool = True) -> Dict:
        """Run MTS with quantum-seeded initial population"""
        results = {}
        
        # Step 1: Quantum sampling
        if verbose:
            print("\n[Step 1] SELNC Quantum Sampling...")
        
        t0 = time.perf_counter()
        
        if self.selnc_available:
            quantum_result = self.selnc.sample(
                n_shots=quantum_shots, 
                n_steps=quantum_steps
            )
            quantum_population = [s['sequence'] for s in quantum_result['samples']]
            quantum_time = time.perf_counter() - t0
            
            results['quantum'] = {
                'time': quantum_time,
                'best_quantum_energy': quantum_result['best_energy'],
                'unique_samples': quantum_result['n_unique'],
                'stats': quantum_result['stats']
            }
            
            if verbose:
                print(f"  Quantum time: {quantum_time:.3f}s")
                print(f"  Best quantum energy: {quantum_result['best_energy']:.2f}")
                print(f"  Unique samples: {quantum_result['n_unique']}")
        else:
            quantum_population = None
            results['quantum'] = {'time': 0, 'error': 'SELNC not available'}
        
        # Step 2: MTS with quantum seed
        if verbose:
            print("\n[Step 2] GPU-MTS with Quantum Seed...")
        
        mts_result_q = self.mts.run(initial_population=quantum_population, verbose=verbose)
        
        results['mts_quantum'] = {
            'best_energy': mts_result_q.best_energy,
            'best_solution': mts_result_q.best_solution.tolist(),
            'energy_history': mts_result_q.energy_history,
            'timing': mts_result_q.timing,
            'device': mts_result_q.device
        }
        
        if verbose:
            print(f"\n  MTS time: {mts_result_q.timing['total']:.3f}s")
            print(f"  Best energy: {mts_result_q.best_energy:.2f}")
        
        return results
    
    def run_random_seeded(self, verbose: bool = True) -> Dict:
        """Run MTS with random initial population (baseline)"""
        if verbose:
            print("\n[Baseline] GPU-MTS with Random Seed...")
        
        mts_result = self.mts.run(initial_population=None, verbose=verbose)
        
        return {
            'best_energy': mts_result.best_energy,
            'best_solution': mts_result.best_solution.tolist(),
            'energy_history': mts_result.energy_history,
            'timing': mts_result.timing,
            'device': mts_result.device
        }
    
    def run_comparison(self, quantum_shots: int = 100,
                       quantum_steps: int = 10,
                       verbose: bool = True) -> Dict:
        """Run full comparison: quantum-seeded vs random-seeded"""
        results = {}
        
        # Quantum-seeded run
        quantum_results = self.run_quantum_seeded(quantum_shots, quantum_steps, verbose)
        results.update(quantum_results)
        
        # Random-seeded baseline
        random_results = self.run_random_seeded(verbose)
        results['mts_random'] = random_results
        
        # Compute comparison metrics
        q_energy = results['mts_quantum']['best_energy']
        r_energy = results['mts_random']['best_energy']
        q_time = results['mts_quantum']['timing']['total']
        r_time = results['mts_random']['timing']['total']
        
        results['comparison'] = {
            'energy_improvement': r_energy - q_energy,
            'energy_improvement_pct': ((r_energy - q_energy) / r_energy * 100) if r_energy > 0 else 0,
            'quantum_is_better': q_energy < r_energy,
            'time_overhead': q_time - r_time if 'quantum' in results else 0
        }
        
        if verbose:
            print("\n" + "=" * 60)
            print("COMPARISON RESULTS")
            print("=" * 60)
            print(f"Quantum-seeded best energy: {q_energy:.2f}")
            print(f"Random-seeded best energy:  {r_energy:.2f}")
            print(f"Improvement: {results['comparison']['energy_improvement']:.2f} "
                  f"({results['comparison']['energy_improvement_pct']:.1f}%)")
            print(f"Quantum advantage: {'YES' if results['comparison']['quantum_is_better'] else 'NO'}")
        
        return results

# =============================================================================
# MAIN / TESTING
# =============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("Enhanced GPU-MTS with SELNC Integration - Test Run")
    print("=" * 70)
    
    # Test configuration
    N = 15
    config = MTSConfig(
        num_generations=30,
        pop_size=15,
        tabu_iterations=50,
        use_gpu=GPU_AVAILABLE
    )
    
    print(f"\nTest Parameters:")
    print(f"  N = {N}")
    print(f"  Generations = {config.num_generations}")
    print(f"  Population size = {config.pop_size}")
    print(f"  GPU Available = {GPU_AVAILABLE}")
    
    # Run hybrid workflow
    hybrid = QuantumEnhancedMTS(N, config)
    results = hybrid.run_comparison(quantum_shots=50, quantum_steps=8, verbose=True)
    
    # Print timing breakdown
    print("\n" + "=" * 60)
    print("TIMING BREAKDOWN (Quantum-Seeded MTS)")
    print("=" * 60)
    timing = results['mts_quantum']['timing']
    for key, value in timing.items():
        print(f"  {key}: {value:.3f}s")
    
    # Verify physical correctness
    print("\n" + "=" * 60)
    print("PHYSICAL CORRECTNESS VERIFICATION")
    print("=" * 60)
    
    best_seq = np.array(results['mts_quantum']['best_solution'])
    e_orig = labs_energy_cpu(best_seq)
    e_neg = labs_energy_cpu(-best_seq)
    e_rev = labs_energy_cpu(best_seq[::-1])
    
    print(f"  energy(S) = {e_orig:.2f}")
    print(f"  energy(-S) = {e_neg:.2f}")
    print(f"  energy(reverse(S)) = {e_rev:.2f}")
    
    assert e_orig >= 0, "Energy must be non-negative"
    assert abs(e_orig - e_neg) < 1e-6, "Negation symmetry violated"
    assert abs(e_orig - e_rev) < 1e-6, "Reversal symmetry violated"
    print("  âœ“ All physical correctness checks passed!")
    
    print("\n" + "=" * 70)
    print("GPU-MTS Test Complete")
    print("=" * 70)
